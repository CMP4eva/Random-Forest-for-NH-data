# (Cleaned and prepped data for the Random Forest)

# Select the predictors and target.
X = nhc_rf_test.drop(['cdc_outbreak'], axis = 1)

y = np.array(nhc_rf_test['cdc_outbreak'])

# Set the seed to 1.
seed = 1

# Split into the training and test sets.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=seed)

# SMOTE
sm = SMOTE(random_state=seed)
X_train, y_train = sm.fit_sample(X_train,y_train)

vars_rf = list(X)
X.head(5)

# Set model parameters
forest = RandomForestClassifier(criterion = 'gini',
                                n_estimators = 500,
                                random_state = 1)

# Fit the saved model to your training data.
forest.fit(X_train, y_train)

# Predict on test data.
y_predict_forest = forest.predict(X_test)

# Look at the first few predictions.
print(y_predict_forest[0:50,])

# Take a look at test data confusion matrix.
conf_matrix_forest = metrics.confusion_matrix(y_test, y_predict_forest)
print(conf_matrix_forest)
accuracy_forest = metrics.accuracy_score(y_test, y_predict_forest)
print("Accuracy for random forest on test data: ", accuracy_forest)

# Compute accuracy using training data.
acc_train_forest = forest.score(X_train, y_train)

print ("Train Accuracy:", acc_train_forest)

# Create a dictionary with accuracy values for model 
model_final_dict = {'metrics': ["accuracy"],
               'values':[round(accuracy_forest,4)],
                'model':['random_forest_05312020']}
model_final = pd.DataFrame(data = model_final_dict)
print(model_final)

nhc_rf_features = nhc_rf_test.drop('cdc_outbreak', axis = 1)
features = nhc_rf_features.columns
importances = forest.feature_importances_
indices = np.argsort(importances)[::-1]
top_indices = indices[0:10][::-1]

plt.figure(1)
plt.title('Feature Importance')
plt.barh(range(len(top_indices)), importances[top_indices], color = 'b', align = 'center')
labels = features[top_indices]
labels = [ '\n'.join(wrap(l,30)) for l in labels ]
plt.yticks(range(len(top_indices)), labels)
plt.xlabel('Relative Importance')

# Predict on test.
forest_y_predict = forest.predict(X_test)
print(forest_y_predict[:5])
#Predict on test, but instead of labels
# we will get probabilities for class 0 and 1.
forest_y_predict_prob = forest.predict_proba(X_test)
print(forest_y_predict_prob[5:])

def get_performance_scores(y_test, y_predict, y_predict_prob, eps=1e-15, beta=0.5):

    from sklearn import metrics

    # Scores keys.
    metric_keys = ["accuracy", "precision", "recall", "f1", "fbeta", "log_loss", "AUC"]

    # Score values.
    metric_values = [None]*len(metric_keys)

    metric_values[0] = metrics.accuracy_score(y_test, y_predict)
    metric_values[1] = metrics.precision_score(y_test, y_predict)
    metric_values[2] = metrics.recall_score(y_test, y_predict)
    metric_values[3] = metrics.f1_score(y_test, y_predict)
    metric_values[4] = metrics.fbeta_score(y_test, y_predict, beta=beta)
    metric_values[5] = metrics.log_loss(y_test, y_predict_prob[:, 1], eps=eps)
    metric_values[6] = metrics.roc_auc_score(y_test, y_predict_prob[:, 1])

    perf_metrics = dict(zip(metric_keys, metric_values))

    return(perf_metrics)

forest_scores = get_performance_scores(y_test, forest_y_predict, forest_y_predict_prob)

ensemble_methods_metrics = {"RF": forest_scores}
print(ensemble_methods_metrics)

rf_roc = metrics.plot_roc_curve(forest, X_test, y_test, name = "RF")
plt.show()

pickle.dump(forest, open("nhc_covid19_rfmodel.sav","wb" ))

#optimized random forest
forest.get_params()

# Number of trees in random forest.
n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 20)]

# Number of features to consider at every split.
max_features = ['auto', 'sqrt']

# Maximum number of levels in tree.
max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
max_depth.append(None)

# Minimum number of samples required to split a node.
min_samples_split = [2, 5, 10]

# Minimum number of samples required at each leaf node.
min_samples_leaf = [1, 2, 4]

# Set Minimal Cost-Complexity Pruning parameter (has to be >= 0.0).
ccp_alpha = [0.0, 0.001, 0.01, 0.1, 0.2, 0.3]

# Create the random grid
# (a python dictionary in a form `'parameter_name': parameter_values`)
random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'ccp_alpha': ccp_alpha}

print(random_grid)

rf_random = pickle.load(open("rf_random_0627.sav","rb"))
# Pass best parameters obtained through randomized search to RF classifier.
optimized_forest = RandomForestClassifier(**rf_random.best_params_)

# Train the optimized RF model.
optimized_forest.fit(X_train, y_train)

# Get predicted labels for test data.
optimized_forest_y_predict = optimized_forest.predict(X_test)

# Get predicted probabilities.
optimized_forest_y_predict_proba = optimized_forest.predict_proba(X_test)
# Compute performance scores.
optimized_forest_scores = get_performance_scores(y_test,
optimized_forest_y_predict,
optimized_forest_y_predict_proba)


# Take a look at test data confusion matrix.
conf_matrix_forest_opt = metrics.confusion_matrix(y_test, optimized_forest_y_predict)
print(conf_matrix_forest_opt)
accuracy_forest_opt = metrics.accuracy_score(y_test, optimized_forest_y_predict)
print("Accuracy for random forest on test data: ", accuracy_forest_opt)

plt.clf()
plt.imshow(conf_matrix_forest_opt, interpolation='nearest', cmap=plt.cm.tab20)
classNames = ['Negative','Positive']
plt.title('Nursing Home Compare Outbreak Confusion Matrix - Test Data')
plt.ylabel('True label')
plt.xlabel('Predicted label')
tick_marks = np.arange(len(classNames))
plt.xticks(tick_marks, classNames, rotation=45)
plt.yticks(tick_marks, classNames)
s = [['TN','FP'], ['FN', 'TP']]
for i in range(2):
    for j in range(2):
        plt.text(j-0.25,i, str(s[i][j])+" = "+str(conf_matrix_forest_opt[i][j]))
plt.show()

nhc_rf_features_opt = nhc_rf_test.drop('cdc_outbreak', axis = 1)
features = nhc_rf_features.columns
importances = optimized_forest.feature_importances_
indices = np.argsort(importances)[::-1]
top_indices = indices[0:10][::-1]

plt.figure(1)
plt.title('Feature Importance')
plt.barh(range(len(top_indices)), importances[top_indices], color = 'b', align = 'center')
labels = features[top_indices]
labels = [ '\n'.join(wrap(l,30)) for l in labels ]
plt.yticks(range(len(top_indices)), labels)
plt.xlabel('Relative Importance')

opt_rf_roc = metrics.plot_roc_curve(optimized_forest,
                                    X_test,
                                    y_test,
                                    name = "Optimized RF",
                                    )

plt.show()

optimized_forest_scores = get_performance_scores(y_test, optimized_forest_y_predict, optimized_forest_y_predict_proba)

pickle.dump(optimized_forest, open("nhc_covid19_rfmodel_optimized.sav","wb" ))

# aaaaand someone else coded the prediction for teh next date
